{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy,sys,time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "import string\n",
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input(input_file):\n",
    "    with open(input_file, 'rb') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            yield gensim.utils.simple_preprocess(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34850946, 50344940)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = read_input('data.tsv')\n",
    "# build vocabulary and train model\n",
    "doc_list = [d for d in doc]\n",
    "model = gensim.models.Word2Vec(\n",
    "        doc_list,\n",
    "        size=150,\n",
    "        window=10,\n",
    "        min_count=1,\n",
    "        workers=10)\n",
    "model.train(doc_list, total_examples=len(doc_list), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/datasets/home/56/656/haa001/.local/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('anything', 0.7059581279754639),\n",
       " ('things', 0.5725936889648438),\n",
       " ('nothing', 0.5648808479309082),\n",
       " ('whatever', 0.535612940788269),\n",
       " ('everything', 0.5327731370925903),\n",
       " ('it', 0.5194367170333862),\n",
       " ('what', 0.5147068500518799),\n",
       " ('someone', 0.5136159062385559),\n",
       " ('stuff', 0.4700457453727722),\n",
       " ('intra', 0.4530140161514282)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = 'something'\n",
    "model.wv.most_similar(positive=w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.2865996 ,  0.05312096, -0.15904526, -0.36874214,  0.93098485,\n",
       "       -0.41446996,  0.9292068 , -0.5055322 , -0.49235085, -0.85127765,\n",
       "        1.0466743 ,  0.55201286,  0.48503098,  1.1396943 ,  0.47737584,\n",
       "        0.16407704,  0.08244048,  0.23501381,  0.41852632,  0.568707  ,\n",
       "        0.9552854 , -0.46423876,  0.10247459,  0.27861083,  1.2197453 ,\n",
       "        0.35090977, -0.49689606,  0.31761396, -0.07180959,  0.6022233 ,\n",
       "       -0.8020828 ,  0.11679435,  0.18990673,  0.6967766 , -1.5653837 ,\n",
       "        0.45386153,  0.20344369,  0.46711898, -0.642616  ,  0.3891348 ,\n",
       "       -0.3411015 ,  0.82972777, -0.09639759, -0.45927635, -0.7186664 ,\n",
       "       -0.06674694,  0.16246893, -0.51936454, -1.1227741 ,  0.30203584,\n",
       "       -0.6738462 ,  0.44886115, -0.08223097, -0.00431547, -0.6888116 ,\n",
       "        0.3094585 , -0.02324419,  0.22051877,  0.38138956,  0.58008736,\n",
       "        0.6846353 ,  0.78361344, -0.41444343,  0.38082018,  0.6819345 ,\n",
       "        0.90999985, -0.39837572, -0.75698006, -1.382539  ,  0.53735524,\n",
       "       -0.52606076, -0.44586006,  0.4964004 ,  0.05522169, -0.60523856,\n",
       "       -0.04489962, -0.06458754, -0.3081313 , -0.17671642,  0.7794495 ,\n",
       "        0.15519026,  0.49247417,  0.0099045 ,  0.8465481 ,  0.41512316,\n",
       "       -0.69905174, -0.5961423 ,  0.77250516, -0.50785744,  0.28504026,\n",
       "        0.41994825,  0.05491596, -0.02160295, -0.22752486,  0.5435067 ,\n",
       "       -0.7959914 , -0.3838685 ,  0.34339055, -0.41636518,  0.14933273,\n",
       "       -0.18284045,  0.6631171 ,  0.36801672,  0.37636438, -0.996512  ,\n",
       "        0.6630657 ,  0.30474952, -0.58523434, -1.1671656 , -0.28287417,\n",
       "        0.14764008, -0.56297857, -0.26782885,  0.5643239 ,  0.75591904,\n",
       "        0.11867311,  0.00506328,  0.42298162,  0.78862184, -0.70381045,\n",
       "       -0.44267005, -0.2862681 , -1.240133  ,  0.9601074 , -0.15242653,\n",
       "        0.8885075 ,  0.51402205, -0.07365056,  0.88460237, -0.23945124,\n",
       "       -0.69036883,  0.28986117,  0.6867958 , -0.2066551 ,  1.0931484 ,\n",
       "        0.26528513, -0.32760668, -0.2573707 , -1.1705006 , -0.0777315 ,\n",
       "        0.36420116, -0.18704222, -0.58743024, -0.6698858 ,  0.38654238,\n",
       "       -0.5715062 , -0.82168204,  0.52015465, -0.47862935, -0.7403581 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['computers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/datasets/home/56/656/haa001/.local/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('men', 1.0),\n",
       " ('women', 0.7996717691421509),\n",
       " ('girls', 0.6573750972747803),\n",
       " ('males', 0.6254711151123047),\n",
       " ('females', 0.6128126978874207)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "your_word_vector = model.wv['men']\n",
    "model.wv.most_similar(positive=[your_word_vector], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 5\n",
    "dataX = []\n",
    "dataY = []\n",
    "for haiku_list in doc_list:\n",
    "    for i in range(0, len(haiku_list)-1-seq_length):\n",
    "        seq_in=haiku_list[i:i+seq_length]\n",
    "        seq_out=haiku_list[i+seq_length]\n",
    "        dataX.append([model.wv[w] for w in seq_in])\n",
    "        dataY.append(model.wv[seq_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('can', 0.9999999403953552), ('cant', 0.7830692529678345), ('cannot', 0.7410323023796082), ('could', 0.7139013409614563), ('will', 0.6706205010414124)]\n",
      "[('you', 0.9999999403953552), ('they', 0.6642903089523315), ('we', 0.57551109790802), ('yourself', 0.5415840744972229), ('others', 0.4377296566963196)]\n",
      "[('see', 1.0), ('hear', 0.5801050662994385), ('imagine', 0.5390194058418274), ('know', 0.5318241119384766), ('tell', 0.5078991055488586)]\n",
      "[('how', 1.0), ('what', 0.5031564831733704), ('where', 0.4781579375267029), ('why', 0.4342767000198364), ('so', 0.4271538555622101)]\n",
      "[('much', 0.9999999403953552), ('far', 0.5101966857910156), ('deeply', 0.4690285325050354), ('brisk', 0.4514276385307312), ('frequently', 0.4510418772697449)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/datasets/home/56/656/haa001/.local/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "for v in dataX[0]:\n",
    "    print(model.wv.most_similar(positive=[v], topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'data.tsv'\n",
    "# raw_text=open(filename,'r').read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_text = raw_text.replace('<br>', ' ')\n",
    "# processed_text = raw_text.replace('\\n', ' ')\n",
    "# raw_text = ''.join([c for c in raw_text if not c in string.punctuation])\n",
    "# processed_text = ''.join([c for c in processed_text if not c in string.punctuation])\n",
    "# words=sorted(list(set(processed_text.split(' '))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_to_int = dict((c,i) for i, c in enumerate(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_words = len(processed_text.split(' '))\n",
    "# n_vocab = len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq_length = 5\n",
    "# lines = raw_text.split('\\n')\n",
    "# dataX = []\n",
    "# dataY = []\n",
    "# for haiku in lines:\n",
    "#     haiku_list = haiku.split(' ')\n",
    "#     haiku_list = [h for h in haiku_list if h != '']\n",
    "#     for i in range(0, len(haiku_list)-1-seq_length):\n",
    "#         seq_in=haiku_list[i:i+seq_length]\n",
    "#         seq_out=haiku_list[i+seq_length]\n",
    "#         dataX.append([word_to_int[w] for w in seq_in])\n",
    "#         dataY.append(word_to_int[seq_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_patterns = len(dataX)\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, len(dataX[0][0])))\n",
    "# X = X/float(n_vocab)\n",
    "y = np_utils.to_categorical(dataY)\n",
    "# y = dataY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]),return_sequences=True))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(LSTM(256,input_shape=(X.shape[1], X.shape[2]),return_sequences=True))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(LSTM(256,input_shape=(X.shape[1], X.shape[2]),return_sequences=True))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "# model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.add(Dense(len(y), activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = np_utils.to_categorical(dataY)\n",
    "# X = dataX\n",
    "model.fit(X, y, epochs=1, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# int_to_word=dict((i,c) for i,c in enumerate(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(int(time.time()))\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print('pattern is', pattern)\n",
    "\n",
    "sys.stdout.write(\"Generated Haiku: \")\n",
    "generated=' '.join([int_to_word[value] for value in pattern])\n",
    "\n",
    "syllables_count = 0\n",
    "\n",
    "for i in range(10):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = ' ' + int_to_word[index] \n",
    "    #seq_in = [int_to_word[value] for value in pattern]\n",
    "    #sys.stdout.write(result)\n",
    "    generated+=result\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "sys.stdout.write(\"%s\\n\"%generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
