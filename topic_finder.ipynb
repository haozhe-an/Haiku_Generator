{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"data.tsv\"\n",
    "raw_text=open(filename,'r').read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "import string\n",
    "from collections import defaultdict\n",
    " \n",
    "    \n",
    "# Find popular words mentioned in the dataset to determine topics of haiku\n",
    "stop_words = set(stopwords.words('english')) \n",
    "punctuation = set(string.punctuation)\n",
    "\n",
    "word_dict = defaultdict(int)\n",
    "for w, prop in nltk.pos_tag(word_tokenize(raw_text)):\n",
    "    w = ''.join([c for c in w if not c in punctuation])\n",
    "    if w in stop_words or w =='br' or w == '':\n",
    "        continue\n",
    "    elif prop == 'NN':\n",
    "        word_dict[w] += 1\n",
    "            \n",
    "popularWords = [(word_dict[x], x) for x in word_dict]\n",
    "popularWords.sort()\n",
    "popularWords.reverse()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import common_texts, get_tmpfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input(input_file):\n",
    "    with open(input_file, 'rb') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            yield gensim.utils.simple_preprocess(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34740628, 50344940)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = read_input('data.tsv')\n",
    "# build vocabulary and train model\n",
    "doc_list = [d for d in doc]\n",
    "model = gensim.models.Word2Vec(\n",
    "        doc_list,\n",
    "        size=150,\n",
    "        window=10,\n",
    "        min_count=2,\n",
    "        workers=10)\n",
    "model.train(doc_list, total_examples=len(doc_list), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Herman/anaconda3/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('anything', 0.7117910385131836),\n",
       " ('nothing', 0.5874983072280884),\n",
       " ('whatever', 0.5577409267425537),\n",
       " ('things', 0.5481641292572021),\n",
       " ('someone', 0.5237470865249634),\n",
       " ('everything', 0.5168544054031372),\n",
       " ('it', 0.5111933946609497),\n",
       " ('what', 0.5087223052978516),\n",
       " ('stuff', 0.47133585810661316),\n",
       " ('snowflake', 0.45040780305862427)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = 'something'\n",
    "model.wv.most_similar(positive=w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.2642795 , -0.51795095,  0.67204547, -0.38518867,  1.0278109 ,\n",
       "        0.1024085 , -0.05360449,  0.31515282, -0.23021771, -0.7869888 ,\n",
       "       -2.0556011 , -0.85081035,  0.7705266 ,  0.36268896, -1.2520938 ,\n",
       "        2.0300279 ,  0.06054727, -1.1553769 ,  1.5840745 , -0.02483731,\n",
       "        2.2633948 ,  0.5388736 ,  0.53490126,  0.9022774 , -0.6825171 ,\n",
       "       -0.4778896 ,  1.7844342 , -0.7965914 , -1.1970766 ,  0.6596457 ,\n",
       "        0.53584594,  0.41376653,  0.36950696, -1.5192869 , -0.7544989 ,\n",
       "        0.9097853 , -1.4788796 ,  2.0131588 , -0.6739045 , -0.05928412,\n",
       "       -0.45873353, -0.71868694, -1.7373323 , -0.7812943 ,  1.2414864 ,\n",
       "       -0.7297306 ,  0.24165006, -0.6198493 ,  2.5534575 , -1.7465446 ,\n",
       "       -0.93307346, -1.3158338 , -0.23063755,  1.1519043 ,  1.2046088 ,\n",
       "       -0.16371915, -0.95074016, -1.1438292 ,  0.59983766, -1.2115061 ,\n",
       "       -0.32691258, -0.356442  ,  3.9180996 ,  0.7040092 , -0.5911093 ,\n",
       "       -0.64512473, -1.9769596 , -2.3769882 ,  0.898313  , -0.82545465,\n",
       "        0.20048116, -0.38301432,  0.72054505, -0.10478033,  0.05158357,\n",
       "        0.52546716, -0.20123939,  0.17464346,  2.5806468 , -0.49345654,\n",
       "        0.47114545, -0.49648795,  0.44623786, -1.3967644 , -1.3169414 ,\n",
       "       -1.753422  ,  0.34374934,  0.22583504, -1.5962068 ,  1.8259296 ,\n",
       "        0.7243557 ,  1.1065894 , -0.57016754, -0.40899184,  1.3919507 ,\n",
       "       -1.0605885 ,  0.21848509,  3.1431062 ,  0.74108803, -0.18428995,\n",
       "        1.1643609 ,  0.01626109, -1.3184042 , -0.15675986,  1.2868677 ,\n",
       "        1.702363  , -1.4021174 ,  0.9731945 , -0.4023596 , -0.6578227 ,\n",
       "        0.5406262 ,  0.03739312, -1.2439555 , -1.6979976 ,  0.04780517,\n",
       "       -1.429475  , -0.59591883, -0.11322776,  0.6266434 , -1.3456569 ,\n",
       "       -1.5553367 ,  0.51686937, -0.33444092, -0.147938  , -0.37527445,\n",
       "        0.01760238, -2.5975633 , -0.3262312 ,  0.82113385, -0.8015797 ,\n",
       "       -0.35823867,  1.3040991 , -0.28398117,  0.12981935,  0.13260114,\n",
       "        0.12891719, -0.04673177,  1.8823007 ,  0.26282734,  0.3935615 ,\n",
       "        0.28558904, -0.465437  , -1.918896  , -1.8064895 , -0.23775078,\n",
       "        1.8971945 ,  0.6293051 , -0.1496827 ,  0.27867347,  0.6493529 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors = model.wv\n",
    "del model\n",
    "word_vectors['computer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_vectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-851f5c7d8ecd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtopics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'key'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'word_vectors' is not defined"
     ]
    }
   ],
   "source": [
    "topics = ['time', 'game', 'life', 'money', 'person']\n",
    "\n",
    "for t in topics:\n",
    "    print(word_vectors.n_similarity(['key'], [t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_syllables(sentence):\n",
    "    words = sentence.split(' ')\n",
    "    count = 0\n",
    "    for w in words:\n",
    "        count += count_word_syllables(w)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count_syllables' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1da788480565>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcount_syllables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"if you kill yourself\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'count_syllables' is not defined"
     ]
    }
   ],
   "source": [
    "count_syllables(\"if you kill yourself\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_rhymes(word):\n",
    "    url = 'http://rhymebrain.com/en/What_rhymes_with_' + word + '.html'\n",
    "    body = requests.get(url).text\n",
    "    soup = BeautifulSoup(body, 'lxml')\n",
    "    \n",
    "    res = str(soup.find_all(attrs={'class':'wordpanel'}))\n",
    "    res = [x for x in res.split('>') if x.find('wordpanel') == -1]\n",
    "    res = [x.split('<')[0].strip() for x in res if x != \"]\"]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ends', 'lends', 'tends', 'trends', 'sends', 'spends', 'bends', 'blends', 'amends', 'attends', 'ascends', 'offends', 'depends', 'extends', 'descends', 'intends', 'defends', 'pretends', 'commends', 'suspends', 'dividends', 'recommends', 'contends', 'transcends', 'apprehends', 'comprehends', 'rents', 'cents', 'tents', 'scents', 'vents', 'dents', 'events', 'temps', 'laments', 'ferments', 'resents', 'prevents', 'intents', 'descents', 'extents', 'invents', 'consents', 'represents', 'presidents', 'penitents', 'discontents', 'malcontents', 'lens', 'threads', 'reds', 'shreds', 'ens', 'sleds', 'heads', 'legs', 'beds', 'eggs', 'heirs', 'realms', 'spreads', 'tens', 'airs', 'cleanse', 'hens', 'pens', 'sheds', 'dens', 'elms', 'flares', 'gens', 'welds', 'yells', 'breads', 'dreads', 'elves', 'glens', 'treads', 'cells', 'says', 'tears', 'tells', 'bears', 'pairs', 'prayers', 'shares', 'stairs', 'bells', 'cares', 'chairs', 'shells', 'stems', 'theirs', 'wells', 'hairs', 'sells', 'selves', 'shelves', 'spells', 'wares', 'wears', 'begs', 'dares', 'fairs', 'fares', 'gels', 'gems', 'smells', 'swells', 'theorems', 'belles', 'dregs', 'hares', 'mares', 'pears', 'pegs', 'snares', 'spares', 'stares', 'swears', 'webs', 'scares', 'tares', 'affairs', 'hotels', 'repairs', 'squares', 'dwells', 'arrowheads', 'farewells', 'overheads', 'repels', 'spectres', 'themselves', 'ourselves', 'declares', 'upstairs', 'prepares', 'yourselves', 'cartels', 'impairs', 'morphemes', 'thoroughfares', 'excels', 'impels', 'motels', 'overwhelms', 'parallels', 'compares', 'downstairs', 'compels', 'condemns', 'organelles', 'unawares', 'watersheds', 'millionaires', 'questionnaires']\n"
     ]
    }
   ],
   "source": [
    "res = find_rhymes('friends')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
