{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"data.tsv\"\n",
    "raw_text=open(filename,'r').read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "import string\n",
    "from collections import defaultdict\n",
    " \n",
    "    \n",
    "# Find popular words mentioned in the dataset to determine topics of haiku\n",
    "stop_words = set(stopwords.words('english')) \n",
    "punctuation = set(string.punctuation)\n",
    "\n",
    "word_dict = defaultdict(int)\n",
    "for w, prop in nltk.pos_tag(word_tokenize(raw_text)):\n",
    "    w = ''.join([c for c in w if not c in punctuation])\n",
    "    if w in stop_words or w =='br' or w == '':\n",
    "        continue\n",
    "    elif prop == 'NN':\n",
    "        word_dict[w] += 1\n",
    "            \n",
    "popularWords = [(word_dict[x], x) for x in word_dict]\n",
    "popularWords.sort()\n",
    "popularWords.reverse()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import common_texts, get_tmpfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input(input_file):\n",
    "    with open(input_file, 'rb') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            yield gensim.utils.simple_preprocess(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1710620)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = read_input('data.tsv')\n",
    "# build vocabulary and train model\n",
    "doc_list = [d for d in doc]\n",
    "model = gensim.models.Word2Vec(\n",
    "        doc_list,\n",
    "        size=150,\n",
    "        window=10,\n",
    "        min_count=2,\n",
    "        workers=10)\n",
    "model.train(documents, total_examples=len(documents), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('anything', 0.7419047355651855),\n",
       " ('nothing', 0.6539467573165894),\n",
       " ('everything', 0.6414459943771362),\n",
       " ('whatever', 0.5973901152610779),\n",
       " ('things', 0.5681877136230469),\n",
       " ('someone', 0.5593835711479187),\n",
       " ('what', 0.546806275844574),\n",
       " ('somewhere', 0.5425013303756714),\n",
       " ('it', 0.5078710317611694),\n",
       " ('somebody', 0.5009409189224243)]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = 'something'\n",
    "model.wv.most_similar(positive=w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9.73323703e-01,  2.08198762e+00, -2.10128158e-01, -2.86785513e-01,\n",
       "        9.90558267e-02, -1.00594115e+00, -4.73537445e-01,  5.49311340e-01,\n",
       "       -4.74444449e-01, -4.47383106e-01, -9.73135605e-02,  4.04840916e-01,\n",
       "        7.71569431e-01, -3.92949969e-01, -9.00569558e-01, -6.21932864e-01,\n",
       "        2.33791813e-01, -4.94199106e-03, -1.08655125e-01, -4.73928392e-01,\n",
       "        3.44799727e-01,  4.63811040e-01,  9.16867852e-01, -4.71720308e-01,\n",
       "       -3.67632270e-01, -7.54500151e-01,  8.12745690e-01,  9.77547765e-01,\n",
       "        1.88784504e+00, -7.02458262e-01, -5.75803280e-01, -6.56246662e-01,\n",
       "        9.62911308e-01,  2.23893598e-01, -2.64555603e-01, -2.43403256e-01,\n",
       "        6.08487427e-01, -9.83925611e-02, -1.55332372e-01, -5.93279302e-01,\n",
       "       -6.24090195e-01, -6.73266053e-01, -3.28264345e-04,  2.36745123e-02,\n",
       "       -1.96712792e-01, -2.64582396e-01,  2.24361926e-01, -2.20137969e-01,\n",
       "        2.28568569e-01, -3.01982164e-01,  7.86104143e-01, -3.83211732e-01,\n",
       "        1.24233282e+00, -6.34737790e-01, -4.14575756e-01,  4.35811549e-01,\n",
       "        6.04388833e-01,  1.37812436e-01, -5.87759018e-01, -1.10397220e+00,\n",
       "       -1.44068480e-01,  9.62502323e-03, -2.83969223e-01,  2.30074376e-01,\n",
       "       -1.37260780e-01, -1.11388192e-01,  5.49067616e-01, -4.21168543e-02,\n",
       "        1.13846071e-01,  2.74551809e-01,  4.41887200e-01,  1.12463248e+00,\n",
       "       -6.17429376e-01,  3.67671520e-01,  3.20292890e-01,  8.17731619e-01,\n",
       "        2.49253556e-01, -1.13979854e-01,  6.55008733e-01, -7.73449093e-02,\n",
       "       -4.81136233e-01, -7.72808716e-02, -6.20138943e-02, -7.76209474e-01,\n",
       "       -3.28385293e-01,  1.30088717e-01,  4.09465909e-01, -9.58541930e-02,\n",
       "        1.60514385e-01,  1.41869234e-02, -1.53044716e-01, -1.58729091e-01,\n",
       "        7.65308917e-01, -2.92223781e-01,  2.54256368e-01, -6.56306446e-01,\n",
       "        1.90572366e-02, -4.79421407e-01,  1.02557324e-01, -8.69775116e-02,\n",
       "        5.33629656e-01, -2.91645914e-01,  6.85785830e-01,  4.51020241e-01,\n",
       "       -1.28854454e-01, -7.78303444e-01, -2.09220126e-01,  1.10798895e+00,\n",
       "       -2.02490047e-01, -1.35914862e+00,  9.90600958e-02,  1.72649220e-01,\n",
       "       -8.93826187e-01, -3.25286746e-01,  1.08263803e+00, -5.79421297e-02,\n",
       "       -4.58083510e-01,  1.86673284e-01, -2.65796125e-01, -2.11630642e-01,\n",
       "       -3.79215062e-01,  1.81850642e-01,  3.01264614e-01, -9.00149047e-02,\n",
       "        5.40563464e-01,  5.52740872e-01,  6.83949828e-01, -9.81704235e-01,\n",
       "       -1.87801465e-01, -2.61780173e-01,  8.50762725e-01, -8.98236513e-01,\n",
       "        4.20075618e-02,  3.97476345e-01, -5.02579451e-01, -6.22684181e-01,\n",
       "       -2.43590966e-01, -5.66398859e-01,  2.40494683e-01, -3.05038661e-01,\n",
       "        4.17258829e-01, -5.15250623e-01,  1.32903039e+00, -4.19559538e-01,\n",
       "        5.09291179e-02, -6.61431611e-01, -1.33229971e+00,  5.28533340e-01,\n",
       "       -6.03534430e-02, -7.00253919e-02], dtype=float32)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors = model.wv\n",
    "del model\n",
    "word_vectors['computer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16064775\n",
      "0.26227218\n",
      "0.05648103\n",
      "0.17840178\n",
      "0.05933264\n"
     ]
    }
   ],
   "source": [
    "topics = ['time', 'game', 'life', 'money', 'person']\n",
    "\n",
    "for t in topics:\n",
    "    print(word_vectors.n_similarity(['key'], [t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
